#### Conv-TasNet Setting
name: Conv_Tasnet
# gpu_ids: [0,1,2,3,6,7]
gpu_ids: [0,1]
epochs: 100

#### Dataset Configure
datasets:
  num_workers: 16
  batch_size: 10
  fs: 8000
  # chunk_len: 4
  # chunk_size: 32000 #### fs*chunk_len
  train:
    mix_scp: /lustre/users/shi/datasets/librimix/ConvTasNet/ConvTasNet_Separation_WavLM_CAtt/data/audio_scp_8k/train_360/clean/tr_mix.scp
    ref_scp: 
      - /lustre/users/shi/datasets/librimix/ConvTasNet/ConvTasNet_Separation_WavLM_CAtt/data/audio_scp_8k/train_360/tr_s1.scp
      - /lustre/users/shi/datasets/librimix/ConvTasNet/ConvTasNet_Separation_WavLM_CAtt/data/audio_scp_8k/train_360/tr_s2.scp
    sr: 8000
  val:
    mix_scp: /lustre/users/shi/datasets/librimix/ConvTasNet/ConvTasNet_Separation_WavLM_CAtt/data/audio_scp_8k/dev/clean/cv_mix.scp
    ref_scp: 
      - /lustre/users/shi/datasets/librimix/ConvTasNet/ConvTasNet_Separation_WavLM_CAtt/data/audio_scp_8k/dev/cv_s1.scp
      - /lustre/users/shi/datasets/librimix/ConvTasNet/ConvTasNet_Separation_WavLM_CAtt/data/audio_scp_8k/dev/cv_s2.scp
    sr: 8000

#### training settings: learning rate scheme, loss
train:
  optimizer: adam
  min_lr: !!float 1e-8
  patience: 2
  factor: 0.5
  logging_period: 200
  clip_norm: 200
  num_epochs: 100
  checkpoint: Conv-TasNet-clean100-WavLM-dwconvFuse


optimizer_kwargs:
  lr: !!float 1e-3
  weight_decay: !!float 1e-5

#### network configure
net_conf:
  N: 512
  L: 16
  B: 128
  H: 512
  P: 3
  X: 8
  R: 3
  norm: gln
  num_spks: 2
  activate: relu
  causal: false
  wavlm_name: "microsoft/wavlm-large"
  # wavlm_sep_dim: 796
  attn_dim: 256
  fuse: concat
  ##skip_con: false

#### resume model
resume:
  path: /lustre/users/shi/datasets/librimix/ckpt_convtasnet
  resume_state: true
